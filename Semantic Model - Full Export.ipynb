{"cells":[{"cell_type":"markdown","source":["### This Microsoft Fabric notebook exports all the tables in a Microsoft Fabric Semantic Model as tables in a Microsoft Fabric Lakehouse. It also lists all the measures, including their definition.\n","\n","Author: Luis Soares<br>Contibutor: Andreas Bergstedt\n","\n","Thanks to: https://learn.microsoft.com/en-us/fabric/data-science/read-write-power-bi-spark\n","\n","By default, the workspace used to access semantic models is:\n","- the workspace of the attached Lakehouse or\n","- the workspace of the notebook, if no Lakehouse is attached."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b5064d34-099d-498a-9002-4a05a66e54a4"},{"cell_type":"code","source":["%pip install semantic-link\n","%load_ext sempy"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8d8b15d4-4643-47c5-b82d-9067bc98869d"},{"cell_type":"code","source":["# change these 3 parameters acording to your environment\n","\n","workspace_name        = \"Microsoft Fabric Capacity Metrics\" # workspace name where the semantic model is\n","semantic_model_name   = \"Fabric Capacity Metrics\"           # semantic model name\n","target_lakehouse_name = \"Fabric_Capacity_Metrics_LH\"        # target lakehouse name (must be added as source)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3b8fe783-435c-4222-95c1-e892d28135ad"},{"cell_type":"code","source":["import sempy.fabric as fabric\n","import pyspark.sql.functions as F\n","df_datasets = fabric.list_datasets(workspace_name) # datasets are semantic models\n","df_datasets"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"14f175c5-0ace-462d-91b8-16593d57be4a"},{"cell_type":"code","source":["# this is not needed for an export, but gives a visual relationship between tables\n","\n","from sempy.relationships import plot_relationship_metadata\n","\n","relationships = fabric.list_relationships(semantic_model_name, workspace = workspace_name)\n","plot_relationship_metadata(relationships)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15f7748a-f159-4b73-881d-f35659c8e3cd"},{"cell_type":"code","source":["df_tables = fabric.list_tables(semantic_model_name, workspace = workspace_name) # list all tables from a semantic model\n","df_tables"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4c78b1b8-4ab6-4df5-be3b-455a80807583"},{"cell_type":"code","source":["# use this cell to show a specific table. not needed to export data\n","df_test = fabric.read_table(semantic_model_name, \"Dates\", workspace = workspace_name)\n","df_test.head(10)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"4d13d050-6661-40d6-92f7-dd4690e5b71b"},{"cell_type":"code","source":["total_tables = df_tables.shape[0]\n","lakehouse_path = \"/\" + target_lakehouse_name + \"/Tables/\"\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n","\n","for index, row in df_tables.iterrows():\n","    table_name = row[\"Name\"]\n","    print(f\"Exporting table {index + 1}/{total_tables}: {table_name}\")\n","\n","    if(table_name == \"All Measures\"): # this table can't be execute because it has no columns. will be handled after\n","        print(\"Skipping...\")\n","        continue\n","\n","    # https://learn.microsoft.com/en-us/fabric/data-engineering/lakehouse-notebook-load-data\n","    pd_table = fabric.read_table(semantic_model_name, table_name, workspace = workspace_name)\n","\n","    n_rows = pd_table.shape[0]\n","    print(\"# rows:\", n_rows)\n","    if(n_rows == 0):            # if a table is empty in the semantic model, we can't infer the column types\n","        print(\"Skipping...\")\n","        continue\n","\n","    df_table = spark.createDataFrame(pd_table)\n","\n","    df_table_renamed_collumns = df_table\n","    for col in df_table.columns:\n","        df_table_renamed_collumns = df_table_renamed_collumns.withColumnRenamed(col, col.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\"))\n","\n","    # write as a table in the lakehouse\n","    df_table_renamed_collumns.write.mode(\"overwrite\").format(\"delta\").saveAsTable(table_name.replace(\" \", \"_\"))\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"a7c10f11-97a8-46c6-92d9-9931f4c83220"},{"cell_type":"code","source":["df_measures = fabric.list_measures(semantic_model_name, workspace = workspace_name)\n","display(df_measures)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"232c7520-0936-4924-ac6c-331636aae82f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"eff8eaa4-d1cc-4686-b0d1-0c4f5b9f9c70","default_lakehouse_name":"Fabric_Capacity_Metrics_LH","default_lakehouse_workspace_id":"ef92c83b-ceef-4aaa-99cc-cc3672dbca5f"}}},"nbformat":4,"nbformat_minor":5}